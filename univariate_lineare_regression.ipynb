{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "from lineare_regression import linear_hypothesis, cost_function, compute_new_theta, train_univariate_linear_regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generierung von Zufallsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_random_data():\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, 1], [1, 1.2]]\n",
    "    cov = [[1, 1], [1, 2]]\n",
    "    random_data = np.random.multivariate_normal(mean, cov, 50)\n",
    "    return random_data.T\n",
    "\n",
    "def normal_random_data(m, b, x_min, x_max, sample_size, mean, std):\n",
    "    linear_func = lambda x: m * x + b\n",
    "    random_data = np.zeros((sample_size, 2))\n",
    "    normal_random_data = np.random.normal(loc=mean, scale=std, size=sample_size)\n",
    "    for i, x in np.ndenumerate(np.linspace(x_min, x_max, sample_size)):\n",
    "        random_data[i][0] = x\n",
    "        random_data[i][1] = linear_func(x) + normal_random_data[i]\n",
    "        \n",
    "    return random_data.T\n",
    "        \n",
    "#x, y = multivariate_normal_random_data()\n",
    "x, y = normal_random_data(m=0.3, b=2, x_min=0, x_max=5, sample_size=50, mean=0, std=0.3)\n",
    "\n",
    "plt.plot(x, y, \"x\")\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementierung der Hypothese\n",
    "\n",
    "Erstellung einer linearen Hypothese mit $\\theta_0$ und $\\theta_1$. Ausgabe des Ergebnisses dieser für die $x$-Werte 1 und 2.\n",
    "\n",
    "$h_\\theta(x)=\\theta_0+\\theta_1x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = 2.\n",
    "theta_1 = 3.\n",
    "\n",
    "h = linear_hypothesis(theta_0, theta_1)\n",
    "\n",
    "test_x_values = [1., 2.]\n",
    "print(h(np.array(test_x_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementierung der Kostenfunktion\n",
    "$J_D(\\theta)=\\frac{1}{2m}\\sum^{m}_{i=1}{(h_\\theta(x_i)-y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = cost_function(linear_hypothesis, x, y)\n",
    "\n",
    "print(j(2.1, 2.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Contourplot der Kostenfunktion in der Umgebung des Minimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0_min = 0\n",
    "theta_1_min = 1.1\n",
    "step = 0.05\n",
    "range_offset = 4\n",
    "\n",
    "possible_theta_0 = np.arange(theta_0_min - range_offset, theta_0_min + range_offset, range_offset * step)\n",
    "possible_theta_1 = np.arange(theta_1_min - range_offset, theta_1_min + range_offset, range_offset * step)\n",
    "\n",
    "costs = np.zeros([len(possible_theta_0), len(possible_theta_1)])\n",
    "cost_func = cost_function(linear_hypothesis, x, y)\n",
    "\n",
    "for i, current_theta_0 in enumerate(possible_theta_0):\n",
    "    for j, current_theta_1 in enumerate(possible_theta_1):\n",
    "        costs[j][i] = cost_func(current_theta_0, current_theta_1)\n",
    "\n",
    "theta_0_mat, theta_1_mat = np.meshgrid(possible_theta_0, possible_theta_1)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.contour(theta_0_mat, theta_1_mat, costs)\n",
    "plt.xlabel(\"$\\Theta_0$\")\n",
    "plt.ylabel(\"$\\Theta_1$\")\n",
    "plt.title(\"cost function\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Gradientenabstiegsverfahren\n",
    "Update Rule: $\\theta_{j_{neu}}\\leftarrow\\theta_{j_{alt}}-\\alpha*\\frac{\\delta}{\\delta\\theta_{j_{alt}}}J(\\theta_{alt})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_y, theta_0, theta_1 = train_univariate_linear_regression(x=x, y=y,\n",
    "                                                              start_theta_0=0.5,\n",
    "                                                              start_theta_1=1.5,\n",
    "                                                              learning_rate=0.001,\n",
    "                                                              iterations=5000)\n",
    "cost_x = np.arange(0, len(cost_y))\n",
    "\n",
    "plt.title(\"learning progress\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"costs\")\n",
    "plt.plot(cost_x, cost_y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modell (Fit-Gerade) + Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_line_x = x\n",
    "fit_line_y = []\n",
    "hypothesis = linear_hypothesis(theta_0, theta_1)\n",
    "for x_with_another_name_because_jupyter_notebook_is_shit in fit_line_x:\n",
    "    fit_line_y.append(hypothesis(x_with_another_name_because_jupyter_notebook_is_shit))\n",
    "    \n",
    "plt.plot(x, y, \"x\")\n",
    "plt.plot(fit_line_x, fit_line_y)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training mit verschiedenen $\\alpha$'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001, 0.003, 0.01, 0.03, 0.1]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    cost_y, theta_0, theta_1 = train_univariate_linear_regression(x=x, y=y,\n",
    "                                                                  start_theta_0=0.5,\n",
    "                                                                  start_theta_1=1.5,\n",
    "                                                                  learning_rate=learning_rate,\n",
    "                                                                  iterations=1000)\n",
    "    cost_x = np.arange(0, len(cost_y))\n",
    "    plt.plot(cost_x, cost_y, label=\"α = {}\".format(learning_rate))\n",
    "\n",
    "plt.title(\"learning progress\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"costs\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
